{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f106525-b75d-4fc1-b7c9-f35dcdd0a757",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/07 14:04:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10-16-195-6.dynapool.wireless.nyu.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa3a88f0d30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf()\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a734906f-f61d-442e-90d4-b3d644825abb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=============================>                             (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- behavior_type: integer (nullable = true)\n",
      " |-- item_category: integer (nullable = true)\n",
      " |-- time: timestamp (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- hour: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Import user dataset \n",
    "df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"/Users/yxwen/Desktop/BigData/FinalProj/tianchi_mobile_recommend_train_user.csv\")\n",
    "# Clean the data - delete unrelevant column 'item_geohash'\n",
    "df = df.drop(\"user_geohash\")\n",
    "# num1 = df.count()\n",
    "# delete outlier (invalid value) \n",
    "df1 = df.na.drop()\n",
    "# num2 = df1.count()\n",
    "# print(num1, num2)\n",
    "# consistent processing: separate 'time' column to 'data' and 'hour'\n",
    "df_user = df1.withColumn(\"date\", split(\"time\", \" \").getItem(0))\n",
    "df_user = df_user.withColumn(\"hour\", split(\"time\", \" \").getItem(1))\n",
    "# convert the data to date data type and time to timestamp data type\n",
    "df_user = df_user.withColumn(\"date\", to_date(\"date\", \"yyyy-MM-dd\"))\n",
    "df_user = df_user.withColumn(\"hour\", to_timestamp(\"hour\", \"HH:mm:ss\"))\n",
    "df_user.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bfeff32-592f-46c1-a771-25f94bfabef1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2876947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11550581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 101:=====================>                                   (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\"\"\" Overview Count \"\"\"\n",
    "# Find total number of items \n",
    "num_item = df_user.select(\"item_id\").distinct().count()\n",
    "print(num_item)\n",
    "# Find total number of categories\n",
    "num_categories = df_user.select(\"item_category\").distinct().count()\n",
    "print(num_categories)\n",
    "# Find total number of click\n",
    "num_behavior_1 = df_user.filter(df_user.behavior_type == 1).count()\n",
    "print(num_behavior_1)\n",
    "# Find total number of favorite\n",
    "num_behavior_2 = df_user.filter(df_user.behavior_type == 2).count()\n",
    "print(num_behavior_2)\n",
    "# Find total number of add to shopping cart\n",
    "num_behavior_3 = df_user.filter(df_user.behavior_type == 3).count()\n",
    "print(num_behavior_3)\n",
    "# Find total number of purchase\n",
    "num_behavior_4 = df_user.filter(df_user.behavior_type == 4).count()\n",
    "print(num_behavior_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea00198-3ed2-4ae9-87fe-7ad1a08ac147",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" What products do users want to find on Taobao? \"\"\"\n",
    "# Find top 5 values according to the 'item_category'\n",
    "# count according to 'item_category' when 'behavior_type' == 1\n",
    "df_filtered = df_user.filter(col(\"behavior_type\") == 1)\n",
    "df_grouped = df_filtered.groupBy(\"item_category\").agg(count(\"*\").alias(\"category_count\"))\n",
    "df_topCategory = df_grouped.orderBy(col(\"category_count\").desc()).limit(5)\n",
    "df_topCategory.show()\n",
    "# df_final.write.mode(\"overwrite\").json(\"/Users/yxwen/Desktop/BigData/FinalProj/top5Category.json\")\n",
    "\n",
    "# Find top 3 items in each category\n",
    "# count according to 'item_id' when 'behavior_type' == 1\n",
    "\n",
    "# Create a list of the top 5 item categories\n",
    "top5_categories = df_topCategory.select(\"item_category\").rdd.flatMap(lambda x: x).collect()\n",
    "# Filter the rows in df_filtered to only include the top 5 categories\n",
    "df_filtered_top5 = df_filtered.filter(col(\"item_category\").isin(top5_categories))\n",
    "# Group the filtered rows by both \"item_category\" and \"item_id\", and count the number of occurrences\n",
    "df_item_counts = df_filtered_top5.groupBy(\"item_category\", \"item_id\").agg(count(\"*\").alias(\"item_count\"))\n",
    "# Define a window specification that partitions the rows by \"item_category\" and orders them by \"item_count\" in descending order\n",
    "w = Window.partitionBy(\"item_category\").orderBy(col(\"item_count\").desc())\n",
    "# Add a new column to df_item_counts that ranks the rows by \"item_count\" within each \"item_category\"\n",
    "df_item_counts_ranked = df_item_counts.withColumn(\"rank\", dense_rank().over(w))\n",
    "# Keep only the rows with a rank of 1, 2, or 3\n",
    "df_final = df_item_counts_ranked.filter(col(\"rank\") <= 3).drop(\"rank\")\n",
    "# df_final.show()\n",
    "\n",
    "# Write the df_final dataframe to a new JSON file\n",
    "df_final.write.mode(\"overwrite\").json(\"/Users/yxwen/Desktop/BigData/FinalProj/top3InCategory.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996109bb-d1fe-4852-ba89-b0c70fd57593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" When users are used to buying products? \"\"\"\n",
    "# df_user.printSchema()\n",
    "# Count according to 'date'\n",
    "# Extract data by top 5 categories found before with behavior_type==4 which represent \"buy\"\n",
    "df_filtered_2 = df_user.filter((col(\"item_category\").isin(top5_categories)) & (col(\"behavior_type\") == 4))\n",
    "df_filtered_2.printSchema()\n",
    "# Count each item according to what each category in each date\n",
    "df_grouped = df_filtered_2.groupBy(\"item_category\", \"date\")\\\n",
    "                   .agg(count(\"*\").alias(\"item_count\"))\n",
    "# Sort in desending order\n",
    "df_grouped_date = df_grouped.orderBy(desc(\"item_count\"))\n",
    "df_grouped_date.show()\n",
    "\n",
    "# Count according to 'hour'\n",
    "df_grouped = df_filtered_2.groupBy(\"item_category\", \"hour\")\\\n",
    "                   .agg(count(\"*\").alias(\"item_count\"))\n",
    "# Sort in desending order\n",
    "df_grouped_time = df_grouped.orderBy(desc(\"item_count\"))\n",
    "df_grouped_time.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0bd19e1-c302-4f84-ba42-94474557fbb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|item_category|category_count|\n",
      "+-------------+--------------+\n",
      "|         1863|          2000|\n",
      "|         6513|          1059|\n",
      "|         5894|           958|\n",
      "|         5027|           858|\n",
      "|        13230|           841|\n",
      "+-------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 124:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|item_category|category_count|\n",
      "+-------------+--------------+\n",
      "|         6344|          2208|\n",
      "|         1863|          2000|\n",
      "|         5232|          1611|\n",
      "|         6977|          1324|\n",
      "|         8877|          1072|\n",
      "+-------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\"\"\" Whether the products pushed by Taobao platform meet the needs of users \"\"\"\n",
    "# Demand TOP5 Purchase Situation\n",
    "deman = df_filtered_2.groupBy(\"item_category\").agg(count(\"*\").alias(\"category_count\"))\n",
    "top = deman.orderBy(col(\"category_count\").desc()).limit(5)\n",
    "top.show()\n",
    "# Count top categories when 'behavior_type' == 4\n",
    "filtered = df_user.filter(col(\"behavior_type\") == 4)\n",
    "grouped = filtered.groupBy(\"item_category\").agg(count(\"*\").alias(\"category_count\"))\n",
    "topCategory = grouped.orderBy(col(\"category_count\").desc()).limit(5)\n",
    "topCategory.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d34558-d137-404b-b12b-b5c36d90bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b645184-3780-490f-a1bd-61fe47e1fd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
